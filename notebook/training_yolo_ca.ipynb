{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12454336,"sourceType":"datasetVersion","datasetId":7856244},{"sourceId":481256,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":385854,"modelId":405038}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["!pip install -U --quiet ultralytics albumentations wandb"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:33:35.990012Z","iopub.execute_input":"2025-07-22T03:33:35.990538Z","iopub.status.idle":"2025-07-22T03:35:22.011805Z","shell.execute_reply.started":"2025-07-22T03:33:35.990509Z","shell.execute_reply":"2025-07-22T03:35:22.011064Z"},"id":"4gbLqCzKjE36","outputId":"55ff9d12-fc35-45b6-a185-83be9dd62e0e"},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["import os, yaml, torch, random, numpy as np\n","from ultralytics import YOLO\n","from albumentations import (\n","    Compose, RandomSizedBBoxSafeCrop,RandomBrightnessContrast, HueSaturationValue, MotionBlur,\n","    GaussNoise, CoarseDropout, CLAHE, HorizontalFlip, VerticalFlip,\n","    Affine, OneOf, Resize\n",")\n","import shutil\n","from pathlib import Path"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:49:37.151896Z","iopub.execute_input":"2025-07-22T03:49:37.152549Z","iopub.status.idle":"2025-07-22T03:49:42.069866Z","shell.execute_reply.started":"2025-07-22T03:49:37.152516Z","shell.execute_reply":"2025-07-22T03:49:42.069083Z"},"id":"5Sdw13BWjE3_","outputId":"34f0622e-75db-4666-b5aa-622fcff97fb4"},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["DATA_ROOT = \"/kaggle/input/dataset/merged_dataset_2\"\n","\n","TRAIN_IMAGES = f\"{DATA_ROOT}/train/images\"\n","VAL_IMAGES   = f\"{DATA_ROOT}/valid/images\""],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:49:47.861865Z","iopub.execute_input":"2025-07-22T03:49:47.862601Z","iopub.status.idle":"2025-07-22T03:49:47.866002Z","shell.execute_reply.started":"2025-07-22T03:49:47.862574Z","shell.execute_reply":"2025-07-22T03:49:47.865223Z"},"id":"ULdt7tp1jE4E"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(\"CUDA:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))\n","else:\n","    print(\"âš ï¸  Cháº¡y trÃªn CPU, sáº½ ráº¥t cháº­m!\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:49:50.331060Z","iopub.execute_input":"2025-07-22T03:49:50.331375Z","iopub.status.idle":"2025-07-22T03:49:50.432681Z","shell.execute_reply.started":"2025-07-22T03:49:50.331322Z","shell.execute_reply":"2025-07-22T03:49:50.431968Z"},"id":"ye0e8aYCjE4H","outputId":"81268529-220d-417e-99b4-c5798a6b79fe"},"outputs":[{"name":"stdout","text":"CUDA: True\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class CoordAtt(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super().__init__()\n","        mip = max(8, channels // reduction)\n","\n","        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))\n","        self.pool_w = nn.AdaptiveAvgPool2d((1, None))\n","\n","        self.conv1 = nn.Conv2d(channels, mip, kernel_size=1, stride=1, padding=0)\n","        self.bn1 = nn.BatchNorm2d(mip)\n","        self.act = nn.SiLU()\n","\n","        self.conv_h = nn.Conv2d(mip, channels, kernel_size=1, stride=1, padding=0)\n","        self.conv_w = nn.Conv2d(mip, channels, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        identity = x\n","        n, c, h, w = x.size()\n","\n","        x_h = self.pool_h(x)\n","        x_w = self.pool_w(x).permute(0, 1, 3, 2)\n","\n","        y = torch.cat([x_h, x_w], dim=2)\n","        y = self.act(self.bn1(self.conv1(y)))\n","\n","        x_h, x_w = torch.split(y, [h, w], dim=2)\n","        x_w = x_w.permute(0, 1, 3, 2)\n","\n","        a_h = torch.sigmoid(self.conv_h(x_h))\n","        a_w = torch.sigmoid(self.conv_w(x_w))\n","\n","        return identity * a_h * a_w\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:49:52.096832Z","iopub.execute_input":"2025-07-22T03:49:52.097423Z","iopub.status.idle":"2025-07-22T03:49:52.104312Z","shell.execute_reply.started":"2025-07-22T03:49:52.097391Z","shell.execute_reply":"2025-07-22T03:49:52.103457Z"},"id":"35Sofd4njE4K"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import ultralytics.nn.modules as nn_mod\n","import ultralytics.nn.tasks as y_tasks\n","\n","nn_mod.CoordAtt = CoordAtt\n","y_tasks.CoordAtt = CoordAtt\n","globals()['CoordAtt'] = CoordAtt"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:49:54.398767Z","iopub.execute_input":"2025-07-22T03:49:54.399355Z","iopub.status.idle":"2025-07-22T03:49:54.403207Z","shell.execute_reply.started":"2025-07-22T03:49:54.399306Z","shell.execute_reply":"2025-07-22T03:49:54.402386Z"},"id":"KEQhfASgjE4M"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["%%writefile yolov11s_ca_alb.yaml\n","\n","nc: 5\n","depth_multiple: 1.0\n","width_multiple: 1.0\n","\n","anchors:\n","  - [12,16, 19,36, 40,28]\n","  - [36,75, 76,55, 72,146]\n","  - [142,110, 192,243, 459,401]\n","\n","backbone:\n","  - [-1, 1, Conv, [64, 3, 2]]\n","  - [-1, 1, Conv, [128, 3, 2]]\n","  - [-1, 3, C3, [128]]\n","  - [-1, 1, CoordAtt, [128]]\n","  - [-1, 1, Conv, [256, 3, 2]]\n","  - [-1, 6, C3, [256]]\n","  - [-1, 1, CoordAtt, [256]]\n","  - [-1, 1, Conv, [512, 3, 2]]\n","  - [-1, 6, C3, [512]]\n","  - [-1, 1, SPPF, [512, 5]]\n","\n","head:\n","  - [-1, 3, C3, [512]]\n","  - [-1, 1, Conv, [256, 1, 1]]\n","  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n","  - [[-1, 5], 1, Concat, [1]]\n","  - [-1, 3, C3, [256]]\n","  - [-1, 1, Conv, [128, 1, 1]]\n","  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n","  - [[-1, 2], 1, Concat, [1]]\n","  - [-1, 3, C3, [128]]\n","  - [-1, 1, Conv, [128, 3, 2]]\n","  - [[-1, 14], 1, Concat, [1]]\n","  - [-1, 3, C3, [256]]\n","  - [-1, 1, Conv, [256, 3, 2]]\n","  - [[-1, 10], 1, Concat, [1]]\n","  - [-1, 3, C3, [512]]\n","  - [[8, 11, 14], 1, Detect, [nc]]\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T06:05:33.967521Z","iopub.execute_input":"2025-07-21T06:05:33.968068Z","iopub.status.idle":"2025-07-21T06:05:33.973394Z","shell.execute_reply.started":"2025-07-21T06:05:33.968035Z","shell.execute_reply":"2025-07-21T06:05:33.972756Z"},"id":"mMW-VykgjE4R","outputId":"da2a37c6-5245-44f7-e3d8-5cb73745ec5e"},"outputs":[{"name":"stdout","text":"Writing yolov11s_ca_alb.yaml\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["def get_train_transforms(imgsz=640):\n","    return Compose([\n","        RandomSizedBBoxSafeCrop(width=imgsz, height=imgsz, erosion_rate=0.2, p=0.3),\n","        Resize(imgsz, imgsz, p=1),\n","        HorizontalFlip(p=0.5),\n","        VerticalFlip(p=0.0),\n","        OneOf([\n","            RandomBrightnessContrast(0.2, 0.2, p=0.5),\n","            HueSaturationValue(5, 25, 5, p=0.5)\n","        ], p=0.7),\n","        OneOf([MotionBlur(5, p=0.2), GaussNoise(p=0.2)], p=0.3),\n","        CLAHE(clip_limit=2.0, p=0.3),\n","        CoarseDropout(num_holes=8, max_h_size=64, max_w_size=64, p=0.5),\n","        Affine(rotate=(-10,10), translate_percent=(0.0,0.1), scale=(0.5,1.2), p=0.7)\n","    ], bbox_params={'format':'yolo', 'label_fields':['class_labels']})\n","\n","from ultralytics.data.augment import Albumentations\n","Albumentations.transform = get_train_transforms\n","print(\"Custom Albumentations pipeline registered âœ”ï¸\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:49:59.537620Z","iopub.execute_input":"2025-07-22T03:49:59.538440Z","iopub.status.idle":"2025-07-22T03:49:59.545184Z","shell.execute_reply.started":"2025-07-22T03:49:59.538402Z","shell.execute_reply":"2025-07-22T03:49:59.544540Z"},"id":"zAxkAJVnjE4U","outputId":"8519a280-7c15-429c-988f-d8694733872d"},"outputs":[{"name":"stdout","text":"Custom Albumentations pipeline registered âœ”ï¸\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["model = YOLO(\"/kaggle/input/model_yolov11/other/default/1/best.pt\")\n","    data=\"data.yaml\",\n","    epochs=100,\n","    imgsz=640,\n","    batch=16,\n","    patience=10,\n","    optimizer='SGD',\n","    lr0=0.001,\n","    lrf=0.001,\n","    momentum=0.937,\n","    weight_decay=0.0005,\n","    warmup_epochs=3,\n","    hsv_h=0.0,\n","    hsv_s=0.0,\n","    hsv_v=0.0,\n","    cos_lr=True,\n","    degrees=0.0,\n","    translate=0.0,\n","    scale=0.3,\n","    shear=0.0,\n","    cls=0.7,\n","    perspective=0.0,\n","    flipud=0.0,\n","    fliplr=0.0,\n","    mosaic=1.0,\n","    mixup=0.05,\n","    copy_paste=0.0,\n","    project='runs',\n","    name='yolov11_ca_alb_custom',\n","    device=0,\n","    pretrained=False,\n","    verbose=False,\n","    resume=True\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T03:50:03.723055Z","iopub.execute_input":"2025-07-22T03:50:03.723566Z","iopub.status.idle":"2025-07-22T05:57:04.208307Z","shell.execute_reply.started":"2025-07-22T03:50:03.723544Z","shell.execute_reply":"2025-07-22T05:57:04.207080Z"},"id":"Pz6p7YBXjE4W","outputId":"acd2379c-627e-4832-8070-764bdbebae3b"},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.7, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/input/dataset/merged_dataset_2/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.001, mask_ratio=4, max_det=300, mixup=0.05, mode=train, model=/kaggle/input/model_yolov11/other/default/1/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov11_ca_alb_custom, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=False, profile=False, project=runs, rect=False, resume=/kaggle/input/model_yolov11/other/default/1/best.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/yolov11_ca_alb_custom, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.3, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 3.76MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n  3                  -1  1      3352  CoordAtt                                     [128]                         \n  4                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  5                  -1  6   1118208  ultralytics.nn.modules.block.C3              [256, 256, 6]                 \n  6                  -1  1     12848  CoordAtt                                     [256]                         \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  6   4464640  ultralytics.nn.modules.block.C3              [512, 512, 6]                 \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  3   2495488  ultralytics.nn.modules.block.C3              [512, 512, 3]                 \n 11                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 13             [-1, 5]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 14                  -1  3    690688  ultralytics.nn.modules.block.C3              [512, 256, 3]                 \n 15                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 17             [-1, 2]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3    173312  ultralytics.nn.modules.block.C3              [256, 128, 3]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3    657920  ultralytics.nn.modules.block.C3              [384, 256, 3]                 \n 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 23            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 24                  -1  3   2626560  ultralytics.nn.modules.block.C3              [768, 512, 3]                 \n 25         [8, 11, 14]  1  13458655  ultralytics.nn.modules.head.Detect           [5, [512, 256, 256]]          \nYOLOv11s_ca_alb summary: 241 layers, 28,970,087 parameters, 28,970,071 gradients, 179.6 GFLOPs\n\nTransferred 671/671 items from pretrained weights\nFreezing layer 'model.25.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 16.2MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.1Â±0.2 ms, read: 17.4Â±3.5 MB/s, size: 52.2 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/dataset/merged_dataset_2/train/labels... 5620 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5620/5620 [00:12<00:00, 452.82it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/dataset/merged_dataset_2/train/images/adit_mp4-1357_jpg.rf.cd42ad897bad30838e19f2c8d67fcbf2.jpg: 2 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/dataset/merged_dataset_2/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 23.3Â±2.5 MB/s, size: 54.8 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/dataset/merged_dataset_2/valid/labels... 1808 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1808/1808 [00:03<00:00, 480.32it/s]","output_type":"stream"},{"name":"stdout","text":"WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/dataset/merged_dataset_2/valid is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/yolov11_ca_alb_custom/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 108 weight(decay=0.0), 119 weight(decay=0.0005), 120 bias(decay=0.0)\nResuming training /kaggle/input/model_yolov11/other/default/1/best.pt from epoch 19 to 100 total epochs\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/yolov11_ca_alb_custom\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     19/100      6.19G      1.281      1.194      1.268         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:40<00:00,  2.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.664       0.65      0.645      0.424\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     20/100      6.29G      1.262      1.083      1.258         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:40<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.665      0.666      0.663      0.432\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     21/100      6.27G      1.254       1.07      1.257         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:40<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.663      0.667       0.65      0.424\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     22/100       6.3G      1.246      1.052      1.244         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.664      0.664      0.655      0.431\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     23/100      6.29G      1.224      1.023      1.235         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:40<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.662      0.684      0.655      0.434\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     24/100      6.28G      1.228      1.023      1.227         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.674      0.685      0.652      0.431\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     25/100       6.3G      1.219      1.003       1.23         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.654      0.676      0.642      0.419\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     26/100      6.23G      1.206     0.9938      1.224         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:40<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.676      0.679      0.663      0.441\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     27/100      6.29G        1.2     0.9862      1.215         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635       0.65      0.693      0.643      0.425\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     28/100      6.29G      1.206     0.9801      1.221         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:40<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.662      0.685      0.641      0.422\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     29/100      6.29G      1.187     0.9651      1.213         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635       0.67      0.693       0.65       0.43\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     30/100      6.29G      1.182     0.9537      1.214         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635       0.66      0.696      0.645      0.423\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     31/100      6.28G       1.18     0.9452      1.212         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.672      0.686      0.644      0.427\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     32/100      6.28G      1.175     0.9371      1.206         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.673      0.692      0.661      0.442\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     33/100       6.3G      1.177     0.9391      1.211         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.677      0.687      0.651      0.434\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     34/100      6.22G      1.164     0.9254      1.202         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.669      0.698      0.645       0.43\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     35/100       6.3G      1.159     0.9097      1.197         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:40<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635       0.69      0.677      0.657      0.441\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     36/100      6.29G       1.15     0.9003      1.187         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [06:02<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [00:39<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1808      20635      0.676      0.692      0.641      0.429\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/703 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_avg_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n     37/100      6.27G      1.179     0.9291      1.211         88        640:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 548/703 [04:42<01:20,  1.94it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3203565167.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/model_yolov11/other/default/1/best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train from scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.train(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/input/dataset/merged_dataset_2/data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# ÄÆ°á»ng dáº«n tá»›i file data.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0;31m# Báº¯t Ä‘áº§u vá»›i 100, sáº½ dá»«ng sá»›m náº¿u cáº§n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/loss.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mimgsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# image size (h,w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0manchor_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":null},{"cell_type":"code","source":["model = YOLO(\"/kaggle/working/runs/yolov11_ca_alb_custom/weights/best.pt\")\n","\n","import torch\n","from packaging import version\n","if version.parse(torch.__version__) >= version.parse(\"2.0\"):\n","    model.model = torch.compile(model.model)\n","\n","    print(\"âœ… Model compiled for faster inference\")\n","\n","metrics = model.val(\n","    data=\"/kaggle/input/dataset/merged_dataset_2/data.yaml\",\n","    split=\"test\"\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T08:03:18.882120Z","iopub.execute_input":"2025-07-20T08:03:18.882424Z","iopub.status.idle":"2025-07-20T08:03:57.103650Z","shell.execute_reply.started":"2025-07-20T08:03:18.882380Z","shell.execute_reply":"2025-07-20T08:03:57.102949Z"},"id":"NS_0HbcljE4Z","outputId":"3aee182e-7bb0-4145-d549-dd9128b96412"},"outputs":[{"name":"stdout","text":"âœ… Model compiled for faster inference\nUltralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nYOLOv11s_ca_alb summary (fused): 135 layers, 28,948,647 parameters, 0 gradients, 178.7 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 6.3Â±1.7 MB/s, size: 52.6 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/dataset/merged_dataset_2/test/labels... 877 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 877/877 [00:04<00:00, 179.13it/s]","output_type":"stream"},{"name":"stdout","text":"WARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/dataset/merged_dataset_2/test is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:21<00:00,  2.50it/s]\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        877       9406      0.631      0.751      0.633      0.404\n                   bus        142        180      0.692      0.728      0.683      0.446\n           truck large        336        824      0.732      0.722      0.716      0.451\n          truck medium        343       1197      0.746      0.683      0.716      0.464\n           truck small         19         31      0.126      0.871      0.233      0.168\n                   car        861       7174      0.857      0.749      0.819       0.49\nSpeed: 0.4ms preprocess, 20.8ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mruns/detect/val\u001b[0m\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["!zip -r /kaggle/working/runs/yolov11_ca_alb_custom.zip /kaggle/working/runs/yolov11_ca_alb_custom"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T08:04:52.547913Z","iopub.execute_input":"2025-07-20T08:04:52.548462Z","iopub.status.idle":"2025-07-20T08:04:58.877613Z","shell.execute_reply.started":"2025-07-20T08:04:52.548435Z","shell.execute_reply":"2025-07-20T08:04:58.876796Z"},"id":"MbqMQqDejE4b","outputId":"9afdeed8-8be4-4db1-e3b8-2818211e79fd"},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/runs/yolov11_ca_alb_custom/ (stored 0%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/BoxP_curve.png (deflated 8%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/results.csv (deflated 61%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/train_batch1.jpg (deflated 1%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/confusion_matrix_normalized.png (deflated 20%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/BoxPR_curve.png (deflated 8%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/confusion_matrix.png (deflated 20%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/val_batch1_pred.jpg (deflated 8%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/val_batch2_labels.jpg (deflated 8%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/train_batch2.jpg (deflated 1%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/val_batch0_labels.jpg (deflated 7%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/BoxR_curve.png (deflated 9%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/args.yaml (deflated 52%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/val_batch1_labels.jpg (deflated 9%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/labels_correlogram.jpg (deflated 32%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/val_batch0_pred.jpg (deflated 7%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/BoxF1_curve.png (deflated 9%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/results.png (deflated 9%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/train_batch0.jpg (deflated 1%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/labels.jpg (deflated 36%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/weights/ (stored 0%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/weights/best.pt (deflated 9%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/weights/last.pt (deflated 9%)\n  adding: kaggle/working/runs/yolov11_ca_alb_custom/val_batch2_pred.jpg (deflated 8%)\n","output_type":"stream"}],"execution_count":null}]}